{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75429511",
   "metadata": {},
   "source": [
    "I'll explain LangChain splitters in an intuitive way that'll make it click!\n",
    "\n",
    "## What are Splitters and Why Do We Need Them?\n",
    "\n",
    "Think of it like this: imagine you have a massive textbook but you can only photocopy 5 pages at a time. That's basically what splitters do - they break down large documents into smaller chunks that AI models can actually process.\n",
    "\n",
    "**The core problem:** LLMs have token limits (like Claude can handle ~200k tokens, but smaller models might only handle 4k-8k). Plus, when you're doing retrieval (like RAG - Retrieval Augmented Generation), you want to find the *most relevant* small chunks, not throw entire books at the model.\n",
    "\n",
    "## The Main Types of Splitters\n",
    "\n",
    "### 1. **CharacterTextSplitter** - The Simple One\n",
    "**When to use:** Basic splitting, simple documents, or when you just need something quick.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,        # characters per chunk\n",
    "    chunk_overlap=200,      # overlap between chunks\n",
    "    separator=\"\\n\\n\"        # split on double newlines\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(your_long_text)\n",
    "```\n",
    "\n",
    "- **Input:** A string of text\n",
    "- **Output:** List of smaller text chunks\n",
    "- **How it works:** Counts characters and splits at your separator (like paragraphs)\n",
    "- **Overlap:** The 200-character overlap ensures context isn't lost between chunks. If a sentence gets cut, the overlap catches it.\n",
    "\n",
    "### 2. **RecursiveCharacterTextSplitter** - The Smart One (MOST POPULAR)\n",
    "**When to use:** This is your default choice for most cases!\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # tries these in order\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(your_long_text)\n",
    "```\n",
    "\n",
    "- **Why it's \"recursive\":** It tries to split on big separators first (like paragraphs), then smaller ones (sentences), then spaces, only breaking mid-word as a last resort\n",
    "- **Input:** Text string\n",
    "- **Output:** List of chunks that respect natural boundaries\n",
    "- **Best for:** General text, articles, documentation\n",
    "\n",
    "**Think of it like:** A skilled editor who tries to break chapters into sections, sections into paragraphs, and only cuts mid-sentence if absolutely necessary.\n",
    "\n",
    "### 3. **TokenTextSplitter** - The Precise One\n",
    "**When to use:** When you need exact token counts (for API costs or model limits)\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=500,      # tokens, not characters!\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(your_long_text)\n",
    "```\n",
    "\n",
    "- **Input:** Text string\n",
    "- **Output:** Chunks based on actual tokens (what the model counts)\n",
    "- **Why use it:** Characters ≠ tokens. \"Hello\" is 1 token but 5 characters. This gives you precise control.\n",
    "\n",
    "### 4. **Code Splitters** - For Programming Languages\n",
    "**When to use:** Splitting code files while respecting syntax\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import (\n",
    "    PythonCodeTextSplitter,\n",
    "    Language\n",
    ")\n",
    "\n",
    "python_splitter = PythonCodeTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# Or for other languages\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "```\n",
    "\n",
    "- **Input:** Code as text\n",
    "- **Output:** Chunks that respect functions, classes, logical blocks\n",
    "- **Why use it:** Keeps functions intact, doesn't break mid-class definition\n",
    "\n",
    "### 5. **MarkdownHeaderTextSplitter** - For Markdown\n",
    "**When to use:** You have markdown documents with headers\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "chunks = splitter.split_text(markdown_text)\n",
    "```\n",
    "\n",
    "- **Input:** Markdown text\n",
    "- **Output:** Chunks split by headers, with metadata about which section they're from\n",
    "- **Why use it:** Preserves document structure and hierarchy\n",
    "\n",
    "## Key Parameters Explained\n",
    "\n",
    "**chunk_size:** How big each piece should be (in characters or tokens)\n",
    "- Too small: You lose context\n",
    "- Too large: Won't fit in model, less precise retrieval\n",
    "- Sweet spot: Usually 500-2000 characters depending on use case\n",
    "\n",
    "**chunk_overlap:** How much chunks should overlap\n",
    "- Prevents losing context at boundaries\n",
    "- Usually 10-20% of chunk_size\n",
    "- Example: If chunk_size=1000, overlap=200 is good\n",
    "\n",
    "## Practical Decision Tree\n",
    "\n",
    "```\n",
    "Do you have code?\n",
    "├─ Yes → Use PythonCodeTextSplitter or language-specific splitter\n",
    "└─ No → Continue\n",
    "\n",
    "Do you have markdown with headers?\n",
    "├─ Yes → Use MarkdownHeaderTextSplitter\n",
    "└─ No → Continue\n",
    "\n",
    "Do you need precise token counts?\n",
    "├─ Yes → Use TokenTextSplitter\n",
    "└─ No → Continue\n",
    "\n",
    "Default case:\n",
    "└─ Use RecursiveCharacterTextSplitter (handles 90% of cases well)\n",
    "```\n",
    "\n",
    "## Real Example - Building a RAG System\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Load your document\n",
    "with open(\"big_document.txt\") as f:\n",
    "    document = f.read()\n",
    "\n",
    "# 2. Split it\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = splitter.split_text(document)\n",
    "\n",
    "# 3. Now each chunk can be:\n",
    "# - Embedded (turned into vectors)\n",
    "# - Stored in a vector database\n",
    "# - Retrieved when relevant to a query\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_texts(chunks, embeddings)\n",
    "\n",
    "# 4. Query and get relevant chunks\n",
    "relevant_chunks = vectorstore.similarity_search(\"your question\")\n",
    "```\n",
    "\n",
    "**The flow:**\n",
    "- Input: Big document → Split into chunks → Embed chunks → Store in vector DB → Retrieve relevant chunks → Send to LLM\n",
    "\n",
    "Does this make sense? Any specific splitter you want me to dive deeper into?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c0656",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
