{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c1ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cd87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassio datasets langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.vectorstores import Cassandra\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22465ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#import ur variables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c209387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('budget_speech.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09086ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concantenate\n",
    "raw_text=''\n",
    "for i ,page in enumerate(pdfreader.pages):\n",
    "content=page.extract_text()\n",
    "if content:\n",
    "  rawtext+=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7edf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model_name='mixtral-8x7b-32768',groq_api_key=groq_api_key)\n",
    "embeddings=HuggingFaceEmbeddings(model='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49178583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio # Ensure cassio is imported here if not globally available in this scope\n",
    "astra_vector_store=Cassandra(\n",
    "    embedding=embeddings,\n",
    "    table_name='qa_mini_demo',\n",
    "    session=cassio.get_session(),\n",
    "    keyspace=cassio.get_keyspace()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(\"Inserted %i headlines.\" % len(texts[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c134c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question=True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "    \n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "    if query_text == \"\": \n",
    "        continue\n",
    "    first_question = False\n",
    "\n",
    "print(f\"\\nQUESTION: {query_text}\") \n",
    "answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "print(answer)\n",
    "\n",
    "print(\"FIRST DOCUMENTS BY RELEVANCE\")\n",
    "for doc,score in astra_vector_store.similarity_serach_with_score(query_text,k=4):\n",
    "    print(score,doc.page_content)\n",
    "    print(f'    [{score:.4f}] \"{doc.page_content[:84]} ...\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d4ccf",
   "metadata": {},
   "source": [
    "Nice, this is a **very real-world AI app loop** you‚Äôre looking at. Let‚Äôs slow it down and demystify it completely.\n",
    "\n",
    "First: **yes, this is Python** üêç\n",
    "Nothing exotic. Just a REPL-style loop around a **vector database + LLM**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is this code doing (big picture)\n",
    "\n",
    "> This code creates an **interactive Q&A chatbot** that:\n",
    ">\n",
    "> * Takes a question from the user\n",
    "> * Uses a **vector database (Astra DB)** to retrieve relevant documents\n",
    "> * Uses an **LLM** to generate an answer\n",
    "> * Shows which documents were used (with similarity scores)\n",
    "> * Repeats until the user types `quit`\n",
    "\n",
    "So this is **RAG (Retrieval-Augmented Generation)** in action.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Which language is this?\n",
    "\n",
    "### ‚úÖ Python\n",
    "\n",
    "Clues:\n",
    "\n",
    "* `while True`\n",
    "* `input()`\n",
    "* `.strip()`\n",
    "* `%` string formatting\n",
    "* `.lower()`\n",
    "\n",
    "This is **plain Python**, not LangChain magic.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Line-by-line explanation\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Control variable\n",
    "\n",
    "```python\n",
    "first_question = True\n",
    "```\n",
    "\n",
    "Used to slightly change the prompt text for UX.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Infinite loop (chat loop)\n",
    "\n",
    "```python\n",
    "while True:\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "> Keep asking questions **until user exits**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ User input (first vs next question)\n",
    "\n",
    "```python\n",
    "if first_question:\n",
    "    query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "else:\n",
    "    query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "```\n",
    "\n",
    "Why this exists:\n",
    "\n",
    "* First question ‚Üí different wording\n",
    "* After that ‚Üí ‚Äúnext question‚Äù\n",
    "\n",
    "`.strip()` removes:\n",
    "\n",
    "* leading spaces\n",
    "* trailing spaces\n",
    "* accidental newline\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Exit condition\n",
    "\n",
    "```python\n",
    "if query_text.lower() == \"quit\":\n",
    "    break\n",
    "```\n",
    "\n",
    "* `.lower()` ‚Üí case-insensitive\n",
    "* `break` ‚Üí exit `while True`\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Ignore empty input\n",
    "\n",
    "```python\n",
    "if query_text == \"\":\n",
    "    continue\n",
    "```\n",
    "\n",
    "If user presses Enter without typing:\n",
    "\n",
    "* `continue` ‚Üí skip rest of loop\n",
    "* Ask again\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ After first iteration\n",
    "\n",
    "```python\n",
    "first_question = False\n",
    "```\n",
    "\n",
    "Now the next prompt will say:\n",
    "\n",
    "> ‚ÄúWhat‚Äôs your next question‚Ä¶‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Printing the question\n",
    "\n",
    "```python\n",
    "print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "```\n",
    "\n",
    "Old-school Python formatting:\n",
    "\n",
    "```python\n",
    "\"%s\" % variable\n",
    "```\n",
    "\n",
    "Same as:\n",
    "\n",
    "```python\n",
    "f\"{query_text}\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ üî• The MOST IMPORTANT LINE\n",
    "\n",
    "```python\n",
    "answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "```\n",
    "\n",
    "This is where the magic happens.\n",
    "\n",
    "### What is happening here?\n",
    "\n",
    "1. `query_text` ‚Üí converted to embedding\n",
    "2. Astra DB vector index:\n",
    "\n",
    "   * Finds most relevant documents\n",
    "3. Those documents are sent to the LLM\n",
    "4. LLM generates an answer\n",
    "5. `.strip()` cleans whitespace\n",
    "\n",
    "This is **RAG in one line**.\n",
    "\n",
    "---\n",
    "\n",
    "### What is `astra_vector_index`?\n",
    "\n",
    "Likely:\n",
    "\n",
    "* A wrapper around **Astra DB vector search**\n",
    "* Abstracts:\n",
    "\n",
    "  * embedding\n",
    "  * retrieval\n",
    "  * LLM call\n",
    "\n",
    "Think:\n",
    "\n",
    "```text\n",
    "User Question\n",
    "   ‚Üì\n",
    "Vector Search\n",
    "   ‚Üì\n",
    "Relevant Docs\n",
    "   ‚Üì\n",
    "LLM\n",
    "   ‚Üì\n",
    "Answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Print the answer\n",
    "\n",
    "```python\n",
    "print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "```\n",
    "\n",
    "Just output to console.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Show retrieved documents (transparency üëå)\n",
    "\n",
    "```python\n",
    "print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "```\n",
    "\n",
    "This is **debug / explainability**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Similarity search\n",
    "\n",
    "```python\n",
    "for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "```\n",
    "\n",
    "Meaning:\n",
    "\n",
    "* Convert query ‚Üí embedding\n",
    "* Find top `k=4` most similar docs\n",
    "* Return:\n",
    "\n",
    "  * `doc` ‚Üí document object\n",
    "  * `score` ‚Üí similarity score\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Print relevance + snippet\n",
    "\n",
    "```python\n",
    "print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))\n",
    "```\n",
    "\n",
    "What this prints:\n",
    "\n",
    "* Similarity score (4 decimal places)\n",
    "* First 84 characters of document\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "[0.9123] \"Cassandra is a distributed NoSQL database ...\"\n",
    "```\n",
    "\n",
    "This is **excellent practice** ‚Äî lets you see *why* the answer was generated.\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Objects you didn‚Äôt see defined (but should know)\n",
    "\n",
    "### `astra_vector_store`\n",
    "\n",
    "* Vector DB interface\n",
    "* Stores embeddings + documents\n",
    "\n",
    "### `astra_vector_index`\n",
    "\n",
    "* Higher-level abstraction\n",
    "* Probably wraps:\n",
    "\n",
    "  * retriever\n",
    "  * prompt\n",
    "  * LLM call\n",
    "\n",
    "### `llm`\n",
    "\n",
    "* ChatGPT / Groq / OpenAI / etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ What kind of app is this?\n",
    "\n",
    "This is a:\n",
    "\n",
    "* CLI chatbot\n",
    "* Retrieval-Augmented QA system\n",
    "* Knowledge-base assistant\n",
    "\n",
    "**Exactly the kind of thing companies build.**\n",
    "\n",
    "---\n",
    "\n",
    "## üî• TL;DR (lock this in)\n",
    "\n",
    "* Language ‚Üí **Python**\n",
    "* Pattern ‚Üí **RAG**\n",
    "* Loop ‚Üí CLI chat interface\n",
    "* Vector DB ‚Üí Astra DB\n",
    "* LLM ‚Üí generates final answer\n",
    "* Docs printed ‚Üí transparency & debugging\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Why this code is GOOD\n",
    "\n",
    "‚úî Clean loop\n",
    "‚úî Clear exit condition\n",
    "‚úî Shows retrieved documents\n",
    "‚úî Not hiding magic\n",
    "\n",
    "This is **production-quality learning code**.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next, I can:\n",
    "\n",
    "* Rewrite this in **LangChain LCEL**\n",
    "* Show how Astra DB stores embeddings\n",
    "* Convert this to **Streamlit / Gradio**\n",
    "* Explain similarity scores mathematically\n",
    "* Compare this to OpenAI Assistants API\n",
    "\n",
    "Just say üëä\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1a3b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
