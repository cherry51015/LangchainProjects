{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9dcfa2",
   "metadata": {},
   "source": [
    "Great, this is actually a **very important conceptual question** ‚Äî once you understand this part, Streamlit + LangChain will stop feeling ‚Äúmagical‚Äù and start feeling **logical** üëç\n",
    "I‚Äôll explain **slowly, neatly, and in plain language**, with *why*, *when*, and *how*.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is `session_id` and why is it used?\n",
    "\n",
    "```python\n",
    "session_id = st.text_input(\"Session ID\")\n",
    "```\n",
    "\n",
    "### Think of it like this:\n",
    "\n",
    "A **session** = one continuous conversation / workflow.\n",
    "\n",
    "* User refreshes page ‚Üí session resets ‚ùå\n",
    "* User opens app in new tab ‚Üí new session ‚ùå\n",
    "* But sometimes you WANT:\n",
    "\n",
    "  * multiple chats\n",
    "  * multiple PDFs\n",
    "  * multiple users\n",
    "  * multiple conversations\n",
    "\n",
    "üëâ `session_id` is just a **label** you choose to separate data.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Session ID = \"research_paper_1\"\n",
    "Session ID = \"biology_notes\"\n",
    "Session ID = \"client_A\"\n",
    "```\n",
    "\n",
    "Each session ID can have:\n",
    "\n",
    "* its own PDFs\n",
    "* its own vector database\n",
    "* its own chat history\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ What is `st.session_state` (in one sentence)?\n",
    "\n",
    "> `st.session_state` is **Streamlit‚Äôs memory** that survives reruns.\n",
    "\n",
    "Streamlit reruns your script **top-to-bottom on every interaction**.\n",
    "\n",
    "Without `session_state`:\n",
    "\n",
    "* everything resets\n",
    "* PDFs reload\n",
    "* vectors rebuild\n",
    "* chat history lost\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Why this code exists\n",
    "\n",
    "```python\n",
    "if 'store' not in st.session_state:\n",
    "    st.session_state.store = {}\n",
    "```\n",
    "\n",
    "### What is `store`?\n",
    "\n",
    "`store` is a **dictionary** that holds **multiple sessions**.\n",
    "\n",
    "Structure in memory:\n",
    "\n",
    "```python\n",
    "st.session_state.store = {\n",
    "    \"session_id_1\": <vectorstore_1>,\n",
    "    \"session_id_2\": <vectorstore_2>,\n",
    "}\n",
    "```\n",
    "\n",
    "This allows:\n",
    "\n",
    "* multiple sessions\n",
    "* switching between them\n",
    "* no recomputation\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Why use BOTH `session_id` and `session_state`?\n",
    "\n",
    "| Thing                 | Purpose          |\n",
    "| --------------------- | ---------------- |\n",
    "| `session_id`          | Key (name)       |\n",
    "| `session_state.store` | Storage (memory) |\n",
    "\n",
    "Together:\n",
    "\n",
    "```python\n",
    "st.session_state.store[session_id] = vectorstore\n",
    "```\n",
    "\n",
    "üì¶ Like:\n",
    "\n",
    "* `session_state.store` = cupboard\n",
    "* `session_id` = labeled box inside it\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Understanding `st.file_uploader`\n",
    "\n",
    "```python\n",
    "uploaded_files = st.file_uploader(\n",
    "    \"Choose A PDF file\",\n",
    "    type=\"pdf\",\n",
    "    accept_multiple_files=True\n",
    ")\n",
    "```\n",
    "\n",
    "This:\n",
    "\n",
    "* shows upload button\n",
    "* allows multiple PDFs\n",
    "* returns a **list of UploadedFile objects**\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ The FOR LOOP (very important)\n",
    "\n",
    "```python\n",
    "documents = []\n",
    "\n",
    "for uploaded_file in uploaded_files:\n",
    "```\n",
    "\n",
    "Why loop?\n",
    "üëâ Because user may upload **multiple PDFs**\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-step inside the loop\n",
    "\n",
    "```python\n",
    "with open(uploaded_file, \"wb\") as file:\n",
    "    file.write(uploaded_file.getvalue())\n",
    "    file_name = uploaded_file.name\n",
    "```\n",
    "\n",
    "This:\n",
    "\n",
    "* saves the uploaded PDF to disk\n",
    "* `getvalue()` ‚Üí raw bytes\n",
    "* `\"wb\"` ‚Üí write binary\n",
    "\n",
    "üìå This step is optional unless your loader needs a file path.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "loader = PyPDFLoader(uploaded_file)\n",
    "docs = loader.load()\n",
    "documents.extend(docs)\n",
    "```\n",
    "\n",
    "This:\n",
    "\n",
    "* loads PDF\n",
    "* extracts text page by page\n",
    "* appends to `documents` list\n",
    "\n",
    "After loop:\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    page1_doc,\n",
    "    page2_doc,\n",
    "    page3_doc,\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Text splitting (WHY?)\n",
    "\n",
    "```python\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "```\n",
    "\n",
    "LLMs **cannot handle huge documents at once**.\n",
    "\n",
    "So we:\n",
    "\n",
    "* split into chunks\n",
    "* add overlap to preserve context\n",
    "\n",
    "This produces:\n",
    "\n",
    "```python\n",
    "splits = [chunk1, chunk2, chunk3, ...]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Vector store creation (Chroma)\n",
    "\n",
    "```python\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "```\n",
    "\n",
    "This:\n",
    "\n",
    "* converts text ‚Üí vectors\n",
    "* stores vectors in Chroma DB\n",
    "* allows similarity search\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Retriever (bridge between vectors & LLM)\n",
    "\n",
    "```python\n",
    "retriever = vectorstore.as_retriever()\n",
    "```\n",
    "\n",
    "Retriever:\n",
    "\n",
    "* takes user question\n",
    "* finds relevant chunks\n",
    "* feeds them to LLM\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Where session handling SHOULD happen\n",
    "\n",
    "### Storing per-session vector DB\n",
    "\n",
    "```python\n",
    "st.session_state.store[session_id] = vectorstore\n",
    "```\n",
    "\n",
    "### Retrieving it later\n",
    "\n",
    "```python\n",
    "vectorstore = st.session_state.store[session_id]\n",
    "retriever = vectorstore.as_retriever()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† When to write session-related code\n",
    "\n",
    "### ‚úÖ Use `st.session_state` when:\n",
    "\n",
    "* data must persist across reruns\n",
    "* computation is expensive\n",
    "* chat history needed\n",
    "* vector DB reused\n",
    "\n",
    "### ‚ùå Don‚Äôt use it for:\n",
    "\n",
    "* temporary variables\n",
    "* loop counters\n",
    "* one-time calculations\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Mental Model (VERY IMPORTANT)\n",
    "\n",
    "```\n",
    "Streamlit App\n",
    " ‚îú‚îÄ‚îÄ reruns every interaction\n",
    " ‚îú‚îÄ‚îÄ session_state = memory\n",
    " ‚îú‚îÄ‚îÄ session_id = memory key\n",
    " ‚îî‚îÄ‚îÄ store = dictionary of sessions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ TL;DR (pin this in your head)\n",
    "\n",
    "* `session_id` ‚Üí **name of a session**\n",
    "* `session_state` ‚Üí **memory**\n",
    "* `store` ‚Üí **dictionary of sessions**\n",
    "* for-loop ‚Üí handles **multiple PDFs**\n",
    "* vectorstore ‚Üí stored **per session**\n",
    "* retriever ‚Üí used for Q&A\n",
    "\n",
    "---\n",
    "\n",
    "If you want, next I can:\n",
    "\n",
    "* ‚úçÔ∏è Rewrite this code in a **clean, beginner-friendly way**\n",
    "* üß† Draw a **visual memory diagram**\n",
    "* üß™ Show **buggy vs correct session handling**\n",
    "* üîÑ Add **chat history per session**\n",
    "\n",
    "Just tell me üòä\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489763e",
   "metadata": {},
   "source": [
    "# IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ae088",
   "metadata": {},
   "source": [
    "You‚Äôre not alone ‚Äî **this is the most confusing part of LangChain** for almost everyone.\n",
    "You‚Äôve reached the point where tutorials stop explaining *why* and just throw code.\n",
    "Let‚Äôs **reset your mental model**, then I‚Äôll give you a **one-page cheat sheet + flow chart** you can literally memorize.\n",
    "\n",
    "I‚Äôll explain **conceptually**, not line-by-line code first. Then we‚Äôll map code ‚Üí concept.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† THE BIG IDEA (read this first)\n",
    "\n",
    "You are building a **Conversational RAG system**.\n",
    "\n",
    "That means:\n",
    "\n",
    "> User asks follow-up questions like\n",
    "> ‚ÄúWhat about its limitations?‚Äù\n",
    ">\n",
    "> The system must:\n",
    ">\n",
    "> 1. Understand **what ‚Äúit‚Äù refers to**\n",
    "> 2. Retrieve correct documents\n",
    "> 3. Answer **with memory**\n",
    "\n",
    "---\n",
    "\n",
    "# üîÅ THE 5-STAGE FLOW (THIS IS THE CHEAT SHEET)\n",
    "\n",
    "```\n",
    "User Question\n",
    "   ‚Üì\n",
    "[1] Chat History\n",
    "   ‚Üì\n",
    "[2] Question Reformulation\n",
    "   ‚Üì\n",
    "[3] Retriever\n",
    "   ‚Üì\n",
    "[4] Answer Generator\n",
    "   ‚Üì\n",
    "[5] Memory Update\n",
    "```\n",
    "\n",
    "Memorize this. Everything else is implementation.\n",
    "\n",
    "---\n",
    "\n",
    "# üß© WHAT EACH PART DOES (human explanation)\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Chat History (Memory)\n",
    "\n",
    "**Problem:**\n",
    "User asks:\n",
    "\n",
    "```\n",
    "User: What is LLaMA 3?\n",
    "User: What are its limitations?\n",
    "```\n",
    "\n",
    "Second question is **ambiguous**.\n",
    "\n",
    "So we store chat history.\n",
    "\n",
    "```python\n",
    "ChatMessageHistory()\n",
    "```\n",
    "\n",
    "üì¶ Stored in:\n",
    "\n",
    "```python\n",
    "st.session_state.store[session_id]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Contextualization (History-Aware Question)\n",
    "\n",
    "This part answers:\n",
    "\n",
    "> ‚ÄúWhat is the user *actually* asking, in full?‚Äù\n",
    "\n",
    "### Input:\n",
    "\n",
    "```\n",
    "Chat history + latest question\n",
    "```\n",
    "\n",
    "### Output:\n",
    "\n",
    "```\n",
    "\"What are the limitations of LLaMA 3?\"\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è IMPORTANT:\n",
    "This step **does NOT answer**, it only **rewrites**.\n",
    "\n",
    "That‚Äôs what this prompt does:\n",
    "\n",
    "```python\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"formulate a standalone question...\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Retriever (Document Search)\n",
    "\n",
    "Now we use the **rewritten question** to:\n",
    "\n",
    "```text\n",
    "search vector database ‚Üí get relevant chunks\n",
    "```\n",
    "\n",
    "This is:\n",
    "\n",
    "```python\n",
    "retriever\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ QA Chain (Answering)\n",
    "\n",
    "Now the LLM gets:\n",
    "\n",
    "```\n",
    "Retrieved context + question\n",
    "```\n",
    "\n",
    "And answers concisely.\n",
    "\n",
    "This prompt:\n",
    "\n",
    "```python\n",
    "\"You are an assistant for question-answering tasks...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ RunnableWithMessageHistory (Glue)\n",
    "\n",
    "This is the **most important mental leap**.\n",
    "\n",
    "### What it does:\n",
    "\n",
    "* Automatically:\n",
    "\n",
    "  * stores user messages\n",
    "  * stores assistant responses\n",
    "  * injects chat history next time\n",
    "\n",
    "Without this:\n",
    "‚ùå No memory\n",
    "‚ùå No follow-ups\n",
    "\n",
    "With this:\n",
    "‚úÖ Conversational RAG\n",
    "\n",
    "---\n",
    "\n",
    "# üîÑ COMPLETE FLOW CHART (COPY THIS)\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ User Input   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ RunnableWithMessage    ‚îÇ\n",
    "‚îÇ History                ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Contextualize Question ‚îÇ\n",
    "‚îÇ (history ‚Üí standalone)‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Retriever (Vector DB)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ QA Prompt + LLM        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Answer                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           ‚Üì\n",
    "   Memory Updated\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üß† CODE ‚Üí CONCEPT MAPPING (cheat sheet)\n",
    "\n",
    "| Code                         | Meaning              |\n",
    "| ---------------------------- | -------------------- |\n",
    "| `session_id`                 | Conversation name    |\n",
    "| `st.session_state.store`     | All conversations    |\n",
    "| `ChatMessageHistory()`       | One conversation     |\n",
    "| `MessagesPlaceholder`        | Inject past messages |\n",
    "| `RunnablePassthrough()`      | Forward user input   |\n",
    "| `RunnableWithMessageHistory` | Auto memory          |\n",
    "| `contextualize_q_prompt`     | Rewrite question     |\n",
    "| `retriever`                  | Search documents     |\n",
    "| `qa_prompt`                  | Answer using context |\n",
    "\n",
    "---\n",
    "\n",
    "# üîë WHEN TO USE EACH THING\n",
    "\n",
    "### Use this‚Ä¶\n",
    "\n",
    "| Situation           | Tool                         |\n",
    "| ------------------- | ---------------------------- |\n",
    "| Follow-up questions | History-aware retriever      |\n",
    "| Multiple chats      | `session_id`                 |\n",
    "| Memory              | `RunnableWithMessageHistory` |\n",
    "| Ambiguous questions | Contextualize prompt         |\n",
    "| Large PDFs          | RAG                          |\n",
    "\n",
    "---\n",
    "\n",
    "# üß† FINAL MEMORY HACK (REMEMBER THIS)\n",
    "\n",
    "> **RAG = Search + Answer**\n",
    "> **Conversational RAG = Search + Answer + Memory**\n",
    "\n",
    "---\n",
    "\n",
    "# üèÅ TL;DR (THE ONE-PAGE VERSION)\n",
    "\n",
    "```\n",
    "User\n",
    " ‚Üì\n",
    "Rewrite Question (using history)\n",
    " ‚Üì\n",
    "Retrieve documents\n",
    " ‚Üì\n",
    "Answer\n",
    " ‚Üì\n",
    "Store chat\n",
    "```\n",
    "\n",
    "If you remember **only this**, you‚Äôre already ahead of 90% of people using LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "If you want next:\n",
    "\n",
    "* üß™ I can give you a **MINIMAL conversational RAG example**\n",
    "* üß† A **visual diagram you can screenshot**\n",
    "* üß© A **no-magic version** (everything explicit)\n",
    "\n",
    "Just tell me which one üòä\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed43d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
